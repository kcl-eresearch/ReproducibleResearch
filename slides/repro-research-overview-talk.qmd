---
title: "Seven Steps to Reproducible (Computational) Research"
author: "Liz Ing-Simmons"
format: 
  revealjs:
    self-contained: true
---

## What is reproducibility?

![*The Turing Way* project illustration by Scriberia](fig/reproducible-definit-93a8c9da9e70b9f2b8b165eda8b5fe74.png){width=700,fig-align="center"}

::: {style="font-size: 50%;"}
[The Turing Way Community & Scriberia (2024)](https://doi.org/10.5281/ZENODO.3332807), CC-BY 4.0.
:::

::: notes

Different definitions of reproducibility have been used
The one we'll focus on today is "same data, same analysis, same results"
However having reproducible research often helps make your research replicable, robust, and generalisable too

:::

## The reproducibility crisis

::::: {.columns}

:::: {.column width="50%"}
![Most scientists have experienced failure to reproduce results.](fig/nature_repro_copy.png){width="85%"}

::: {style="font-size: 50%;"}
[Nature, 2016](https://doi.org/10.1038/533452a)
:::

::::

:::: {.column width="50%"}

* Studies that attempt replication have low success rates
* Barriers include:
  * lack of data or experimental reagents
  * incomplete methods
  * unresponsive original authors

::::

:::::


## Why does reproducibility matter?

A lack of reproducibility leads to:

* Time, effort, and funding wasted on follow-up projects
* Loss of trust in research
* Potential for real harm


::: notes

* research should be trustworthy
* avoid waste - wasted time regenerating data, or waste time building on work that isn't reproducible

:::

## Why does reproducibility matter?

Personal benefits to working reproducibly:

:::{.incremental}
* Avoid disaster 
* Make it easier to write your paper/thesis
* Help people understand your work
* Enable continuity of your research
* Build your reputation
:::

:::{style="font-size: 50%;"}
[*Five selfish reasons to work reproducibly*, Markowetz, 2015](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-015-0850-7)
:::

::: notes

disaster: data loss, analysis errors, paper retractions...

:::


## Seven steps

1. Planning to be organised
2. Keeping data tidy
3. Methodology and protocols
4. Testing and controls
5. Automation
6. Documentation
7. Publishing

:::{style="font-size: 50%;"}
Source: [carpentries-incubator.github.io/ReproducibleResearch](https://carpentries-incubator.github.io/ReproducibleResearch)
:::

## Planning to be organised

Before you start a project:

* What data will you collect?
* What code will you write?

## Planning to be organised

How will you organise your data / code?

* Directory structure
* File naming conventions
  * e.g. project-specific abbreviations
  * file names that are both human-readable and computer-readable

## Planning to be organised: tools üîß

:::{.incremental}
* Data Management Plans
  * outline how data will be looked after during and after the project 
  * required by most major funders
* Project templates
  * many examples available - general and domain-specific
  * typically separate documentation, code, raw data, results
:::

::: notes

Structure to document what data you will collect, where it will be stored, who is responsible
Includes any legal or ethical considerations for sensitive / identifiable data
DMPs required by UKRI, Wellcome, DFG, also EU funding

Templates for biology, economics, etc

:::

## Keeping data tidy

::: notes
(this refers to text-based data inside files)
:::

*"each variable is a column, each observation is a row, and each type of observational unit is a table"*

[Wickham, 2014](http://www.jstatsoft.org/v59/i10/)

. . .

* Tidy data facilitates analysis
* Makes data cleaning easier
* Works well with statistical tools

## Keeping data tidy

*"tidy datasets are all alike but every messy dataset is messy in its own way"*

. . .

:::: {.columns}

::: {.column width="50%"}
```{r}
library(tibble)
classroom <- tribble(
  ~name,    ~quiz1, ~quiz2, ~exam1,
  "Billy",  NA,     "D",    "C",
  "Suzy",   "F",    NA,     NA,
  "Lionel", "B",    "C",    "B",
  "Jenny",  "A",    "A",    "B"
  )
classroom
```
:::

::: {.column width="50%"}

```{r}
tribble(
  ~assessment, ~Billy, ~Suzy, ~Lionel, ~Jenny,
  "quiz1",     NA,     "F",   "B",     "A",
  "quiz2",     "D",    NA,    "C",     "A",
  "exam1",     "C",    NA,    "B",     "B"
  )
```
:::

::::

. . .

* Compact and convenient for humans, but not for computers


## Keeping data tidy

:::: {.columns}

::: {.column width="40%"}
```{r}
library(tidyr)
library(dplyr)

classroom %>% 
  pivot_longer(quiz1:exam1, names_to = "assessment", values_to = "grade") %>% 
  arrange(name, assessment)
```
:::

::: {.column width="60%"}

:::{.incremental}
* 3 variables, 12 observations, 36 values
* Each combination of name and assessment is a single measured observation
* Definition of a variable depends on the task
* E.g. what if we wanted to compare quiz and exam scores?
:::

:::

::::

## Keeping data tidy: tools üîß

* Python: `pandas`, `polars`
* R: `tidyr`, `dplyr`, `polars`(*not yet stable)

. . .

‚ÄºÔ∏è but cleaning and tidying your data is no substitute for planning good data organisation in the first place!

## Methodology and protocols

Methods for wet lab work get a lot of attention, but less so for computational work!

Key questions:

* What did you do?
* Why did you do it that way?

## Methodology and protocols

**What** did you do?

:::{.incremental}
* Scripts - document the actual code you ran
* Computational environment - hardware, OS, package versions, random seeds
  * Python: `python -m venv`, `virtualenv`, `pyenv`,...
  * R: `renv`
  * Conda
  * Containers: Docker, Singularity,...
:::

::: notes
compare to running ad hoc commands on commandline / ad hoc analyses
- e.g. renaming files, selecting columns/rows
- e.g. how did you make that plot?
:::

## Methodology and protocols

**Why** did you do it that way?

* Version control e.g. Git
* Literate programming - combine code with text and outputs
  * Jupyter notebooks, RMarkdown, Quarto...
* Code reviews
* Architectural decision records

::: notes

- how many times have you tried something out, discarded it, and then done same again in a future project?

- e.g. Git
- good commit messages can include why you made change
- Donald Knuth introduced the idea of literate programming in 1984
  - higher quality code by forcing programmers to explicitly state their logic and reasoning
  - keep documentation with the code - easier to restart work
  - notebooks are a commonly used tool, but often not used to full potential
- if you work collaboratively on a code base
- process of having to make a merge request and receive a review forces you to explain your work
- for larger projects, you can track decisions about the overall project using ADRs
- e.g. why did you choose a particular package or implementation
:::


## Testing and controls

Is the data what we expect? Does the code do what it should?

:::{.incremental}

* Data validation
  * size and shape, data types, missing data
  * checksums
* Software testing
  * unit tests
  * snapshot testing - does this code still give the same output?
  * integration testing - does everything still work together?
:::

::: notes

For a wetlab scientist, doing controls for an experiment, calibrating hardware is normal
For code?

:::


## Automation

. . .

‚ú®Automate the boring things‚ú®

* Scripts for data cleaning / processing
* Combine scripts into workflows: run a series of data analysis steps in order
* Continuous integration - automatically run your tests

## Automation: tools üîß

* Workflow managers
  * Nextflow: lots of public workflows for bioinformatics
  * Snakemake: Python-based, easy to create your own workflows
* Continuous integration
  * GitHub Actions: lots of templates

::: notes
Github Actions templates for e.g. building and running tests for a python package, for code linting and formatting, etc
:::

## Documentation

*"Documentation is a love letter to your future self"*

Damian Conway, *Perl Best Practices*, 2005

. . .

* Document how all these steps fit together
* Think about what you'd need to tell a new project contributor
* Or what you need to know when someone leaves

::: notes

You've made a plan, organised your work, documented your code, you have automated testing
But if you won the lottery and quit your job tomorrow, would anyone else be able to carry on your project?
Or if you get paper reviews back in six months, would it be easy to pick up and do the revisions?

:::

## Documentation: tools üîß

* `README` 
* (Electronic) lab notebook
  * LabArchives, Benchling, Notion, OneNote...
* Project wiki

## Publishing

. . .

![FAIR principles](fig/fair.avif)

:::{style="font-size: 50%;"}
[Open Science Training Handbook](https://open-science-training-handbook.gitbook.io/book), CC0
:::

::: notes
At the end of a project - hopefully - you'll publish it, maybe as a formal paper, or at least share it with others
What do you need to think about at this stage to ensure reproducibility?

* can people find your data and code? does it have metadata and an unique identifier?
* is it retrievable by humans and machines using standard methods (not carrier pigeon)
  * doesn't have to be open, but should have clarity around who can access
* can data be opened with standard tools? does it use common vocabulary?
  * does code give output in standard formats?
* is there enough documentation? is there a license that tells people how they can use it?

:::


## Publishing: tools üîß

* Persistent identifiers e.g. DOI
  * Data repositories can give a persistent identifier
  * Code can also be submitted to e.g. Zenodo 
  * DOIs can include a version number
* Licensing 
  * check funder requirements / recommendations
  * [choosealicense.com](https://choosealicense.com/) can help you decide


::: notes


:::


